{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE688: Practical and Application of Machine Learning - Spring 2021\n",
    "## Assignment 3-2\n",
    "### Authors\n",
    "\n",
    "- B073040018 朱劭璿\n",
    "- B072010029 陳居廷\n",
    "\n",
    "### References\n",
    "https://www.tensorflow.org/tutorials/text/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment analysis on the sentences in the attachment `hw3-2-dataset`. Classify the sentences into two categories: possitive (1) amd negative (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n",
      "Sentence: The Da Vinci Code book is just awesome.\n",
      "Num samples\": 7086\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = '../hw3-2-dataset/'\n",
    "train_label = []\n",
    "train_data = []\n",
    "with open(DATA_DIR+'training.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for l in lines:\n",
    "    l = l[:-1].split('\\t')\n",
    "    train_label.append(int(l[0]))\n",
    "    train_data.append(l[1])\n",
    "    \n",
    "train_label = np.array(train_label)\n",
    "train_data = np.array(train_data)\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(train_label.shape[0])\n",
    "ds_train = ds_train.batch(32)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print('Label:', train_label[0])\n",
    "print('Sentence:', train_data[0])\n",
    "print('Num samples\":', train_label.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "preprocessing (KerasLayer)      {'input_type_ids': ( 0           text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "BERT_encoder (KerasLayer)       {'default': (None, 5 28763649    preprocessing[0][0]              \n",
      "                                                                 preprocessing[0][1]              \n",
      "                                                                 preprocessing[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           BERT_encoder[0][5]               \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 1)            513         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "classifier_model = build_classifier_model()\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = tf.keras.optimizers.Adam(init_lr)\n",
    "\n",
    "classifier_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "222/222 [==============================] - 29s 130ms/step - loss: 0.0047 - binary_accuracy: 0.9983\n",
      "Epoch 2/2\n",
      "222/222 [==============================] - 29s 131ms/step - loss: 0.0018 - binary_accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21d008f278>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 2\n",
    "classifier_model.fit(\n",
    "    ds_train,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with open(DATA_DIR+'testdata.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "for l in lines:\n",
    "    test_data.append(l[:-1])\n",
    "\n",
    "predicted = []\n",
    "for i in range(0, len(test_data), 256):\n",
    "    predicted.extend(classifier_model(tf.convert_to_tensor(test_data[i:i+256])).numpy().tolist())\n",
    "\n",
    "assert len(test_data) == len(predicted)\n",
    "with open('./result.txt', 'w') as f:\n",
    "    for i in predicted:\n",
    "        f.write(f'{int(i[0] > 0)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
