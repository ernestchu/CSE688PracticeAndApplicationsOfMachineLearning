{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE688: Practical and Application of Machine Learning - Spring 2021\n",
    "## Assignment 5-2\n",
    "### Authors\n",
    "\n",
    "- B073040018 朱劭璿\n",
    "- B072010029 陳居廷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the A2C model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python3 A2C.py \\\n",
    "--load_weights ./weights/baseline.h5 \\\n",
    "--save_weights ./weights/new_weight.h5 \\\n",
    "--save_figure  ./images/result.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode 0 ~ 100,000\n",
    "\n",
    "![](./figures/0-100000.png)\n",
    "\n",
    "### Episode 150,000 ~ 200,000 with more details\n",
    "![](./figures/150000-200000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch the actor network play the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.9.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "2021-05-27 05:07:28.506336: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!python3 play.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the reward\n",
    "Set the `move_reward` to `-dist`, so we can make the snake get close to the food."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python3 A2C.py \\\n",
    "--load_weights ./weights/baseline.h5 \\\n",
    "--save_weights ./weights/new_weight.h5 \\\n",
    "--save_figure  ./images/result.png \\\n",
    "--dist_move_reward True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./figures/dist_reward.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.9.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "2021-05-27 05:07:51.896988: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!python3 play_dist_reward.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another RL application: RAM\n",
    "### RAM (Recurrent Attention Model) [Mnih et al. 2014]\n",
    "In the traditional image classification tasks, the entire image would be fed into the network. However, the object to be classified usually takes up only a partial region out of the entire image. Therefore, we can train a RL network to take **glimpses** on only part of the image, typically reletive small regions. The predicted next glimpse can also be passed in as input at the next timestamp, just like RNN!\n",
    "#### RL characteristics\n",
    "\n",
    "- State: Glimpses seen so far\n",
    "- Action: (x, y ) coordinates of where to look next in the image\n",
    "- Reward: 1 at the finaly timestep if the image is correctly classified, 0 otherwise\n",
    "\n",
    "#### Applications\n",
    "\n",
    "- fine-tuing a trained model ⟶ effectively reducing the inference time.\n",
    "- image captioning\n",
    "- visual question-answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../assets/images/RAM.jpg)\n",
    "\n",
    "> Image credit to cs231n, Stanford University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
