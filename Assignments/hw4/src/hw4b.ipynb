{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE688: Practical and Application of Machine Learning - Spring 2021\n",
    "## Assignment 4b\n",
    "### Authors\n",
    "\n",
    "- B073040018 朱劭璿\n",
    "- B072010029 陳居廷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Please design an autoencoder only for digits 1, 3, 5, 7 in MNIST. Then use the trained autoencoder to detect anomaly data that is not in the set of 1, 3, 5, 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 14312\n",
      "Number of validation samples: 35000\n",
      "Number of testing samples: 35000\n",
      "\n",
      "Label: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from utils import anomaly_detect_split, AnomalyValidation\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "images = np.concatenate((train_images, test_images))\n",
    "labels = np.concatenate((train_labels, test_labels))\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "images = images / 255.0\n",
    "\n",
    "(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    val_images, \n",
    "    val_labels, \n",
    "    test_images, \n",
    "    test_labels\n",
    ") = anomaly_detect_split(images, labels)\n",
    "\n",
    "print(f'Number of training samples: {train_labels.shape[0]}')\n",
    "print(f'Number of validation samples: {val_labels.shape[0]}')\n",
    "print(f'Number of testing samples: {test_labels.shape[0]}')\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_images, train_images)).cache().shuffle(train_labels.shape[0]).batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((val_images, val_images)).cache().batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((test_images, test_images)).cache().batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print()\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "print(f'Label: {train_labels[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 14, 14, 4)         40        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 8)           296       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 16)          1168      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 32)          4640      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 2, 2, 32)          18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 14, 14, 4)         580       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         37        \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28)            0         \n",
      "=================================================================\n",
      "Total params: 48,345\n",
      "Trainable params: 48,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Conv2D(4, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2DTranspose(16, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.ZeroPadding2D(((1, 2), (1, 2))),\n",
    "    tf.keras.layers.Conv2DTranspose(4, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2DTranspose(1, (3, 3), strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Reshape((28, 28))\n",
    "])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "ATH = 0.04 # anomaly confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\u001b[32m Train \u001b[0m MSE:  0.076, \tAnomaly detection accuracy:\u001b[31m  0.04326\u001b[0m\n",
      "Epoch 11\u001b[32m Train \u001b[0m MSE:  0.020, \tAnomaly detection accuracy:\u001b[31m  0.83706\u001b[0m\n",
      "Epoch 21\u001b[32m Train \u001b[0m MSE:  0.017, \tAnomaly detection accuracy:\u001b[31m  0.93809\u001b[0m\n",
      "Epoch 31\u001b[32m Train \u001b[0m MSE:  0.015, \tAnomaly detection accuracy:\u001b[31m  0.96646\u001b[0m\n",
      "Epoch 41\u001b[32m Train \u001b[0m MSE:  0.015, \tAnomaly detection accuracy:\u001b[31m  0.97583\u001b[0m\n",
      "Epoch 51\u001b[32m Train \u001b[0m MSE:  0.014, \tAnomaly detection accuracy:\u001b[31m  0.98346\u001b[0m\n",
      "Epoch 61\u001b[32m Train \u001b[0m MSE:  0.014, \tAnomaly detection accuracy:\u001b[31m  0.98826\u001b[0m\n",
      "Epoch 71\u001b[32m Train \u001b[0m MSE:  0.013, \tAnomaly detection accuracy:\u001b[31m  0.99020\u001b[0m\n",
      "Epoch 81\u001b[32m Train \u001b[0m MSE:  0.013, \tAnomaly detection accuracy:\u001b[31m  0.99154\u001b[0m\n",
      "Epoch 91\u001b[32m Train \u001b[0m MSE:  0.013, \tAnomaly detection accuracy:\u001b[31m  0.99266\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss='mse',\n",
    ")\n",
    "history = autoencoder.fit(\n",
    "    ds_train, \n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    callbacks=[AnomalyValidation(ATH, ds_val, 10)]\n",
    ")\n",
    "# AnomalyValidation callback: Perform anomaly detect on validation dataset\n",
    "#                             Save the best weights and set the weight in training end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection accuracy:  0.99337\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_total = 0\n",
    "for image, label in ds_test:\n",
    "    num_correct += (tf.keras.losses.MSE(autoencoder(image), image).numpy().mean(axis=1) < ATH).sum()\n",
    "    num_total += label.shape[0]\n",
    "print(f'Anomaly detection accuracy: {num_correct/num_total: .5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
