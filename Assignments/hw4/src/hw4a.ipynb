{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE688: Practical and Application of Machine Learning - Spring 2021\n",
    "## Assignment 4a\n",
    "### Authors\n",
    "\n",
    "- B073040018 朱劭璿\n",
    "- B072010029 陳居廷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Please design an classifier only for digits 1, 3, 5, 7 in MNIST. Then use the trained classifier to detect anomaly data that is not in the set of 1, 3, 5, 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 14312\n",
      "Number of validation samples: 35000\n",
      "Number of testing samples: 35000\n",
      "\n",
      "Label: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from utils import anomaly_detect_split, AnomalyValidation\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "images = np.concatenate((train_images, test_images))\n",
    "labels = np.concatenate((train_labels, test_labels))\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "images = images / 255.0\n",
    "\n",
    "(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    val_images, \n",
    "    val_labels, \n",
    "    test_images, \n",
    "    test_labels\n",
    ") = anomaly_detect_split(images, labels)\n",
    "\n",
    "print(f'Number of training samples: {train_labels.shape[0]}')\n",
    "print(f'Number of validation samples: {val_labels.shape[0]}')\n",
    "print(f'Number of testing samples: {test_labels.shape[0]}')\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).cache().shuffle(train_labels.shape[0]).batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).cache().batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).cache().batch(128).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print()\n",
    "plt.imshow(train_images[0], cmap='gray')\n",
    "print(f'Label: {train_labels[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 8)         296       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 16)          1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 6,474\n",
      "Trainable params: 6,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Reshape((28, 28, 1), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Conv2D(4, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-4\n",
    "ATH = 0.8 # anomaly confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\u001b[32m Train \u001b[0m Loss:  2.239, Acc:  0.201\tAnomaly detection accuracy:\u001b[31m  0.59109\u001b[0m\n",
      "Epoch  2\u001b[32m Train \u001b[0m Loss:  1.779, Acc:  0.304\tAnomaly detection accuracy:\u001b[31m  0.59109\u001b[0m\n",
      "Epoch  3\u001b[32m Train \u001b[0m Loss:  0.979, Acc:  0.750\tAnomaly detection accuracy:\u001b[31m  0.65549\u001b[0m\n",
      "Epoch  4\u001b[32m Train \u001b[0m Loss:  0.551, Acc:  0.893\tAnomaly detection accuracy:\u001b[31m  0.73217\u001b[0m\n",
      "Epoch  5\u001b[32m Train \u001b[0m Loss:  0.359, Acc:  0.925\tAnomaly detection accuracy:\u001b[31m  0.74586\u001b[0m\n",
      "Epoch  6\u001b[32m Train \u001b[0m Loss:  0.258, Acc:  0.939\tAnomaly detection accuracy:\u001b[31m  0.70817\u001b[0m\n",
      "Epoch  7\u001b[32m Train \u001b[0m Loss:  0.202, Acc:  0.948\tAnomaly detection accuracy:\u001b[31m  0.68789\u001b[0m\n",
      "Epoch  8\u001b[32m Train \u001b[0m Loss:  0.169, Acc:  0.952\tAnomaly detection accuracy:\u001b[31m  0.65651\u001b[0m\n",
      "Epoch  9\u001b[32m Train \u001b[0m Loss:  0.148, Acc:  0.957\tAnomaly detection accuracy:\u001b[31m  0.64426\u001b[0m\n",
      "Epoch 10\u001b[32m Train \u001b[0m Loss:  0.134, Acc:  0.959\tAnomaly detection accuracy:\u001b[31m  0.63220\u001b[0m\n",
      "Epoch 11\u001b[32m Train \u001b[0m Loss:  0.122, Acc:  0.962\tAnomaly detection accuracy:\u001b[31m  0.62394\u001b[0m\n",
      "Epoch 12\u001b[32m Train \u001b[0m Loss:  0.113, Acc:  0.965\tAnomaly detection accuracy:\u001b[31m  0.61426\u001b[0m\n",
      "Epoch 13\u001b[32m Train \u001b[0m Loss:  0.106, Acc:  0.967\tAnomaly detection accuracy:\u001b[31m  0.61514\u001b[0m\n",
      "Epoch 14\u001b[32m Train \u001b[0m Loss:  0.100, Acc:  0.969\tAnomaly detection accuracy:\u001b[31m  0.60817\u001b[0m\n",
      "Epoch 15\u001b[32m Train \u001b[0m Loss:  0.094, Acc:  0.971\tAnomaly detection accuracy:\u001b[31m  0.60417\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classifier.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "history = classifier.fit(\n",
    "    ds_train, \n",
    "    epochs=15,\n",
    "    verbose=0,\n",
    "    callbacks=[AnomalyValidation(ATH, ds_val)]\n",
    ")\n",
    "# AnomalyValidation callback: Perform anomaly detect on validation dataset\n",
    "#                             Save the best weights and set the weight in training end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly detection accuracy:  0.74637\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0\n",
    "num_total = 0\n",
    "for image, label in ds_test:\n",
    "    confidence = tf.math.reduce_max(tf.nn.softmax(classifier(image)), 1).numpy()\n",
    "    num_correct += ((confidence < ATH) == label.numpy()).sum()\n",
    "    num_total += label.shape[0]\n",
    "print(f'Anomaly detection accuracy: {num_correct/num_total: .5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
