{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE688: Practical and Application of Machine Learning - Spring 2021\n",
    "## Assignment 4e\n",
    "### Authors\n",
    "\n",
    "- B073040018 朱劭璿\n",
    "- B072010029 陳居廷\n",
    "\n",
    "## Results\n",
    "\n",
    "| Approach         | Anomaly Detection Accuracy  |\n",
    "|------------------|-----------------------------|\n",
    "| Classifier-based | 0.739                       |\n",
    "| AE-based         | 0.775                       |\n",
    "| DAE-based        | **0.788**                   |\n",
    "| Isolation Forest | 0.623                       |\n",
    "\n",
    "## Observations\n",
    "### Classifier-based\n",
    "If we train the classifier too well, it would have too much ability on generalizing dataset, thus making the anomaly detection accuracy decrease.\n",
    "```\n",
    "Epoch  3 Train  Loss:  1.009, Acc:  0.815\tAnomaly detection accuracy:  0.59100\n",
    "Epoch  4 Train  Loss:  0.635, Acc:  0.851\tAnomaly detection accuracy:  0.68509\n",
    "Epoch  5 Train  Loss:  0.430, Acc:  0.883\tAnomaly detection accuracy:  0.74026\n",
    "Epoch  6 Train  Loss:  0.326, Acc:  0.905\tAnomaly detection accuracy:  0.71077\n",
    "Epoch  7 Train  Loss:  0.267, Acc:  0.922\tAnomaly detection accuracy:  0.65763\n",
    "Epoch  8 Train  Loss:  0.228, Acc:  0.931\tAnomaly detection accuracy:  0.65443\n",
    "```\n",
    "### AE-based\n",
    "It don't require the lables, and need not see the abnormal data before, yet performing better than the classifier-based model. However, it suffer the same issue of over generalizing as well.\n",
    "```\n",
    "Epoch  2 Train  MSE:  0.052370, \tAnomaly detection accuracy:  0.69986\n",
    "Epoch  3 Train  MSE:  0.037248, \tAnomaly detection accuracy:  0.75383\n",
    "Epoch  4 Train  MSE:  0.030431, \tAnomaly detection accuracy:  0.77694\n",
    "Epoch  5 Train  MSE:  0.027046, \tAnomaly detection accuracy:  0.76946\n",
    "Epoch  6 Train  MSE:  0.025086, \tAnomaly detection accuracy:  0.75811\n",
    "```\n",
    "\n",
    "### DAE-based\n",
    "Also perform well. It's said to be more performant than the regular AE in the literature. Indeed, we see the accuracy is increased by rougly 1%. And again, the model faces the difficulty of over generalizing. We can thus conclude that, in the anomaly detection models, different confidence thresholds (MSE thresholds) should be applied to different training epoch. If we use the same threshold throught out the training, we'll see the accuracy go up and down.\n",
    "\n",
    "```\n",
    "Epoch  1 Train  MSE:  0.067816, \tAnomaly detection accuracy:  0.66394\n",
    "Epoch  2 Train  MSE:  0.046949, \tAnomaly detection accuracy:  0.75743\n",
    "Epoch  3 Train  MSE:  0.035293, \tAnomaly detection accuracy:  0.78874\n",
    "Epoch  4 Train  MSE:  0.030108, \tAnomaly detection accuracy:  0.74680\n",
    "Epoch  5 Train  MSE:  0.026526, \tAnomaly detection accuracy:  0.69457\n",
    "```\n",
    "### Isolation Forest\n",
    "It's not ideal. Isolation Forest doesn't seem to work well on high dimensional data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
